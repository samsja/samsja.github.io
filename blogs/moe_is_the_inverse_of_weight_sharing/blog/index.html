
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Blog post of Samsja">
      
      
      
        <link rel="canonical" href="https://samsja.github.io/blogs/moe_is_the_inverse_of_weight_sharing/blog/">
      
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.14">
    
    
      
        <title>Weight sharing is the inverse of MoE. - Samsja</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.85bb2934.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.a6bdf11c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
        html.glightbox-open { overflow: initial; height: 100%; }
        .gslide-title { margin-top: 0px; user-select: text; }
        .gslide-desc { color: #666; user-select: text; }
        .gslide-image img { background: white; }
        
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
            </style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#weight-sharing-is-the-inverse-of-moe" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Samsja" class="md-header__button md-logo" aria-label="Samsja" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Samsja
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Weight sharing is the inverse of MoE.
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        About
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../" class="md-tabs__link">
        Blogs
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Samsja" class="md-nav__button md-logo" aria-label="Samsja" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    Samsja
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
      
      
      
        <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
          About
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          About
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Blogs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Blogs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        Posts
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#different-levels-of-density" class="md-nav__link">
    Different levels of density
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#disentangle-storage-and-computation" class="md-nav__link">
    Disentangle storage and computation
  </a>
  
    <nav class="md-nav" aria-label="Disentangle storage and computation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#moe-are-shaped-by-hardware-constraint" class="md-nav__link">
    MoE are shaped by hardware constraint
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#super-dense-model-any-use-case" class="md-nav__link">
    Super dense model, any use case?
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion:
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="weight-sharing-is-the-inverse-of-moe">Weight sharing is the inverse of MoE.</h1>
<p><strong>22 june, 2024</strong></p>
<p>MoE/sparse models are less dense than traditional architectures where density is defined as the ratio of total active parameter divided by the number of parameters. What is usually called a "dense model" has a density of 1.0.  </p>
<p>MoEs usually reduce their density by routing tokens to different circuits within the model, increasing the total amount of trainable parameters while keeping the number of active ones constant.  </p>
<h3 id="different-levels-of-density">Different levels of density</h3>
<p>If MoEs are less dense models, what would be a more dense model? (with density &gt;1)  </p>
<p>It's a model where the weights are shared. For instance, a model where a transformer block would be repeated. Each parameter would be used several times, making them more active than in a traditional "dense" model.  </p>
<p>I put dense into a bracket here because it is actually abusing the word, there is no such thing as a dense and non-dense model, just a different density flavor.  </p>
<p>Why does it matter? <strong>Because introducing density as a scale allows us to consider a whole new class of model architectures</strong>.  </p>
<p>We need to move away from the idea that number of parameters should scale on the same path as the number of flops we allow a model to consume. There should be two axes to bigger models, more activations and more weights (more flops and more VRAM).</p>
<h2 id="disentangle-storage-and-computation">Disentangle storage and computation</h2>
<p>Conceptually it actually makes sense to disentangle the storage (weights) from the computation (activations). The former dictates how much data can be compressed, and the latter controls the complexity of the algorithms that can be learned by increasing the number of flops that can be spent at each forward.  </p>
<p>Of course, in practice things are more complex, knowledge / fact and reasoning ability / algorithm are two sides of the same coins.  However, it can be handy to <strong>visualize all of the functions learned by an LLM in a range between <em>purely retrieval</em> and <em>purely algorithmic</em>.</strong> It would actually make sense that the former leverages more weights while the latter leverages more depth or more flops per forward.  </p>
<p>Let's take an example, for a model with an almost infinite storage capacity the easiest way to achieve low perplexity over, let's say a math textbook distribution, is to learn everything by heart. On the other hand, a model with limited storage but infinite flops at runtime will have to learn to predict everything from first principles.</p>
<p><strong>Having these two asymptotes in mind helps reason about the usefulness of different densities of models</strong>.  </p>
<p>It is a known fact that small LLMs (sorry for the oxymoron) have a hard time following instructions. Many concluded that it is because of its too small amount of weight - it's missing a neuron or two -  lol I am funny. What if the real problem was just that the forward pass is too compute limited to be actually able to do anything "smart"?  </p>
<h3 id="moe-are-shaped-by-hardware-constraint">MoE are shaped by hardware constraint</h3>
<p>Okay, enough for the "theoretical" thinking. MoE has emerged because of hardware constraints. They are simply cheaper to train and cheaper to do inference, <em>on our available hardware</em>. </p>
<p>Sparse models have comparable capability to "dense" models at equal weight size, but with an order of magnitude less active parameters, and therefore, less time and less cost to do inference and training. </p>
<p>Let's briefly take a look at the <a href="https://mistral.ai/news/mixtral-of-experts/">Mixtral 8x7b</a> architecture to understand how hardware constraints shaped its design. (Feel free to skip directly to the conclusion)</p>
<p>Let's take a look to understand how it is hardware and cost that shape the design of MoE more than any other factor. Despite its name suggesting 8x7b = 56b parameters, the model is actually 46.7B parameters, with only 12.9B active parameters. Only the feed-forward layer of the transformer blocks are sparsified. Basically, instead of having one feedforward per transformer, there are 8 of them and each token will be directed to 2 feedforwards. Why 8 feedforwards and not 10 or 6? Simply because H100 nodes usually come with 8 GPUs. Each of the GPUs actually hold the equivalent of a 7b model (thus the naming of 8x7b) but with each of them using a different feedforward. </p>
<p>Funny how this 8x7b magically fits into one node of 8x(H100 - 80gig) trained with optimizer and gradient shardings. Well, you would have guessed this is not a coincidence. </p>
<p>TLDR; MoE designs are shaped by hardware constraints, they are cheaper to train than dense models only because some MoE architectures work nicely with high bandwidth inter and intra connect.</p>
<h3 id="super-dense-model-any-use-case">Super dense model, any use case?</h3>
<p>Okay, that was for the hardware constraint that led to the popularization of MoE. So what about the super dense model, a.k.a weight-shared model? Is there some hardware constraint that would make them relevant?  </p>
<p>Yes, local inference (from laptop to mobile). Basically, in local inference, you work most of the time with a batch size 1. Contrary to the model behind an API that receives a constant flow of thousands of users, locally there is only you using your model. Unfortunately, this is totally <a href="https://timdettmers.com/">inefficient for GPU-like chips</a>, and you end up being memory bandwidth bottlenecked most of the time. It is like having to move a pile of books from the library to your table, only to respond to one question of an exam. You would spend most of your time moving books away.</p>
<p>That means that your compute is barely used it is always waiting for the next weights to be loaded from ram/vram to local memory (SRAM).</p>
<p><a class="glightbox" href="../img.png" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="image" src="../img.png" style="height:60%;width:60%" /></a></p>
<p>GPU being idle means that you have room to do more operations for the same cost/time as long as you can reuse the loaded weight while waiting for the next batch of weight to be loaded. Meta actually published a paper about this, <a href="https://arxiv.org/abs/2402.14905">MobileLLM</a>. </p>
<p>Nice explanation from the paper </p>
<pre><code>The SRAM for computing is typically limited to around 20MB. 
This capacity is usually only sufficient to hold a  single 
transformer block. Therefore, placing shared weights in the
cache and computing twice immediately can avoid the need to 
transfer weights between the SRAM and DRAM, resulting in improved 
overall execution speed for auto-regressive inference
</code></pre>
<p>Immediate weight sharing between two blocks can basically double the amount of active parameters while keeping inference time the same. </p>
<h3 id="conclusion">Conclusion:</h3>
<ul>
<li>MoEs are used for an economical reason, driven by hardware constraints.</li>
<li>Let's stop talking about dense and not dense models, density is rather a scale. Different hardware constraints would lead to different density requirements.</li>
<li>Super dense models with shared weights (and reasoning tokens?) could help create a very good small model that would still fit in ram/vram but rival the bigger models in term of performance.</li>
<li>When a 4x1b or 4x8b with some block repeated 4 times for edge?</li>
</ul>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/samsja" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/samsja19" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/sami-jaghouar-805505193/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky"], "search": "../../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.b4d07000.min.js"></script>
      
    
  <script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body>
</html>