
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Blog post of Samsja">
      
      
      
        <link rel="canonical" href="https://samsja.github.io/blogs/rig/part_1/">
      
      
      
      <link rel="icon" href="../../../assets/logo.png">
      <meta name="generator" content="mkdocs-1.4.3, mkdocs-material-9.1.14">
    
    
      
        <title>Building a deep learning rig | part-1 - Samsja</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.85bb2934.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.a6bdf11c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
        html.glightbox-open { overflow: initial; height: 100%; }
        .gslide-title { margin-top: 0px; user-select: text; }
        .gslide-desc { color: #666; user-select: text; }
        .gslide-image img { background: white; }
        
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
            </style> <script src="../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#building-a-deep-learning-rig-part-1" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Samsja" class="md-header__button md-logo" aria-label="Samsja" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Samsja
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Building a deep learning rig | part-1
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
            
              <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
            
            
            
            <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
            
              <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
                <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
              </label>
            
          
        </form>
      
    
    
    
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../.." class="md-tabs__link">
        About
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../" class="md-tabs__link">
        Blogs
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Samsja" class="md-nav__button md-logo" aria-label="Samsja" data-md-component="logo">
      
  <img src="../../../assets/logo.png" alt="logo">

    </a>
    Samsja
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
      
      
      
        <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="0">
          About
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          About
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Index
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Blogs
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Blogs
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        Posts
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#detailed" class="md-nav__link">
    Detailed:
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#deep-learning-and-inter-card-bandwidth" class="md-nav__link">
    Deep learning and inter card bandwidth.
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="building-a-deep-learning-rig-part-1">Building a deep learning rig | part-1</h1>
<p><strong>03 february, 2024</strong></p>
<p>I just got my hands on a mining rig with 3 rtx 3090 founder edition for the modest sum of 1.7k euros.</p>
<p>My plan is to transform it into a deep learning ring, to finetune and serve LLM, play with torch distributed with some MoE as well as doing a bit of independent research.</p>
<p><a class="glightbox" href="../rig_0.jpg" data-type="image" data-width="100%" data-height="auto" data-desc-position="bottom"><img alt="Mining rig" src="../rig_0.jpg" /></a></p>
<h3 id="detailed">Detailed:</h3>
<ul>
<li>rtx 3090 (x3)</li>
<li>Ryzen 5 1600</li>
<li>b450 steel legend</li>
<li>RAM 4gig (lol)</li>
<li>Cooler master 750w silver (x2) </li>
</ul>
<p>Bit of an insane deal, if it was only for the cards it would have cost 560 euro (=1700/3) per cards. In 2024 the price for a second hand 3090 is around 600 / 700. Plus I got all of the other spare part, that I might need to replace. Fun fact two years ago this rig probably would have cost like 7k even with spare part.</p>
<h2 id="deep-learning-and-inter-card-bandwidth">Deep learning and inter card bandwidth.</h2>
<p>The current rig is a mining rig. The three 3090s are connected to the mobo via pci 1X extender. This is totally inefficient for deep learning. </p>
<p>PCI lines are doing the bridge between the the different part of the computer so that they can communicate, a normal gamer pc has usually 24x lines and the gpu is usually using 16x lines. Using 1x mean dividing the normal bandwidth by 16x. It apparently does not matter for crypto mining. Probably because is that in crypto gpu are used to compute the "proof of work" which is basically some brut force algorithm and the bandwidth does not matter, everything stay within the card. But deep learning model take data in (by batch), there is a lot of communication needed between the CPU that pre-process the data and the GPU, thus PCI lines matter.</p>
<h1 id="inter-gpu-bandwidth-choosing-the-number-of-pci-lines">Inter GPU bandwidth, choosing the number of PCI lines</h1>
<p>By looking in the the <a href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/">bible</a> of consumer grade deep learning, we can see that PCI lines x4 "should be enough". </p>
<pre><code>Operating GPUs on 4x lanes is fine, especially if you only have 2 GPUs. For a 4 GPU setup, I would prefer 8x lanes per GPU, but running them at 4x lanes will probably only decrease performance by around 5-10% if you parallelize across all 4 GPUs.
</code></pre>
<p>The CPU on the rig support up to 24 PCI lines and the mobo support <a href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/#Do_I_need_PCIe_40_or_PCIe_50">bifurcation</a>, aka you can split the main x16 lines into 4x4 pci ones. Meaning I could plug my for cards on my main mobo using a PCI riser like this <a href="https://riser.maxcloudon.com/en/bifurcated-risers/22-bifurcated-riser-x16-to-4x4-set.html">one</a> that I found recommended by this excellent deep learning rip <a href="https://nonint.com/2022/05/30/my-deep-learning-rig/">blog post</a>.</p>
<p>It would mean that I only need to add 150 euros more (actually 200 with the shipping cost)  and got my deep learning rig ready. Would have been the cheapest deep learning rig of history.</p>
<p>The alternative is to go with a CPU which has many more cpu lines (the ryzen 5 1600 has only 16) as well as a mobo with at least 3 gpu slots. Problem is even the high end ryzen 9 or intel i9 have only 24 cpu lines ... So I would have to go with a AMD Epyc or Threadripper which are not cheap.</p>
<p>In an ideal word the first option would work out.</p>
<h2 id="is-x4-lines-really-okay-for-deep-learning-with-llm">Is x4 lines really okay for deep learning with LLM ?</h2>
<p>This might depend on the type of GPU parallelism  I want to use. </p>
<h3 id="ddp">DDP</h3>
<p>Few years ago the GPU parallelism was mainly about DDP: distributed data parallelism. The model is replicated on each gpu device, the data is split per gpu, each GPU do a normal forward backward pass on its data, compute the gradient. Then Each GPU shared their gradient via an <a href="https://pytorch.org/docs/stable/distributed.html">All reduce</a> communication (using <a href="https://developer.nvidia.com/nccl">nccl</a>) and each GPU update its internal weights. </p>
<h3 id="fsdp">FSDP</h3>
<p>Large language model are, as they name suggest, larger that their non generative counter parts. GPT3 is 175B parameters, some model even go up to the trillion scale, though usually using some sparse setup (Mixture of Expert) so not really relevant for our calculation.</p>
<p>Nowadays good and large LLM like <a href="https://arxiv.org/abs/2307.09288">llama2</a> is around 70b.</p>
<p>It means that even in int 8 precision the model weight are still 70 GB. The 3090 only have 24gb, so one model does not even fit, not even talking about training. </p>
<p>In this case we need to split the model in chunk. They are multiple way to do this:</p>
<ul>
<li><strong>Pipeline parallelism</strong>: The model is split in chunks, each GPU hold part of the layers. Communication between GPU happened during forward and backward each time that it need to go to the next chunk. Let's say that we split the model on 4 gpus.</li>
</ul>
<p>During forward you need to use the <a href="https://pytorch.org/docs/stable/distributed.html">send</a> operation 3 times because you have 4 chunks. Each send is sending an enter activation.</p>
<ul>
<li><strong>Tensor parallelism</strong>:  Tensor parallelism split the weight of each layer on each gpu. If Pipeline parallelism is splitting the model horizontally tensor parallelism is splitting it vertically. The communication scheme is slightly more complex, I don't fully get, but basically at each layer you need to do a mix of <a href="https://pytorch.org/docs/stable/distributed.html">All-gather</a> and <a href="https://pytorch.org/docs/stable/distributed.html">All-reduce</a> operation. </li>
</ul>
<p>At large scale this two strategy are used alongside data parallelism, that is called 3d parallelism. Checkout <a href="https://github.com/stas00/ml-engineering/tree/master/model-parallelism#dppptp">this blog post</a> for more inf. </p>
<p>In my use case only one of this two strategy will be used alongside DDP.</p>
<p>The conclusion is that such parallelism need more inter gpu communication that pure DDP. <strong>So while PCI lines x4 per gpu might be fine for pure DDP, it might be a huge bottleneck for finetune 70b model</strong>, even worse for local inference that is memory bounded. </p>
<p>Additionally I want to play with Mixture Of Expert, which are sparse model, a.k.a not all weight are used during each forward.  Each "expert" is host on a different GPU and a router dispatch each token into the expert. This of course means a lot more communication that normal DDP.</p>
<h2 id="conclusion">Conclusion</h2>
<p>So I am a bit puzzled, using the 4x pcie Lanes <strong>should work</strong>, but I will be limited for anything that is not DDP like finetune LLM or MoE.</p>
<p>I will investigate the threadripper direction, if it is cheap enough it is probably the best solution, especially if I plan to add a 4 gpus later.</p>
<h1 id="reference">Reference</h1>
<ul>
<li>
<p>Tim Dettmers - <a href="https://timdettmers.com/2023/01/30/which-gpu-for-deep-learning/">Which GPU(s) to Get for Deep Learning: My Experience and Advice for Using GPUs in Deep Learning</a></p>
</li>
<li>
<p><a href="https://shuttletitan.com/miscellaneous/pcie-bifurcation-what-is-it-how-to-enable-optimal-configurations-and-use-cases-for-nvme-sdds-gpus/">PCIe Bifurcation – What is it? How to enable?</a></p>
</li>
<li>
<p><a href="https://pytorch.org/docs/stable/distributed.html">TORCH.DISTRIBUTED</a></p>
</li>
<li>
<p><a href="https://developer.nvidia.com/nccl">nccl</a></p>
</li>
<li>
<p><a href="https://pytorch.org/blog/what-every-user-should-know-about-mixed-precision-training-in-pytorch/">What Every User Should Know About Mixed Precision Training in PyTorch</a> </p>
</li>
<li>
<p><a href="https://arxiv.org/abs/2307.09288">Llama 2</a></p>
</li>
</ul>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/samsja" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 480 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M186.1 328.7c0 20.9-10.9 55.1-36.7 55.1s-36.7-34.2-36.7-55.1 10.9-55.1 36.7-55.1 36.7 34.2 36.7 55.1zM480 278.2c0 31.9-3.2 65.7-17.5 95-37.9 76.6-142.1 74.8-216.7 74.8-75.8 0-186.2 2.7-225.6-74.8-14.6-29-20.2-63.1-20.2-95 0-41.9 13.9-81.5 41.5-113.6-5.2-15.8-7.7-32.4-7.7-48.8 0-21.5 4.9-32.3 14.6-51.8 45.3 0 74.3 9 108.8 36 29-6.9 58.8-10 88.7-10 27 0 54.2 2.9 80.4 9.2 34-26.7 63-35.2 107.8-35.2 9.8 19.5 14.6 30.3 14.6 51.8 0 16.4-2.6 32.7-7.7 48.2 27.5 32.4 39 72.3 39 114.2zm-64.3 50.5c0-43.9-26.7-82.6-73.5-82.6-18.9 0-37 3.4-56 6-14.9 2.3-29.8 3.2-45.1 3.2-15.2 0-30.1-.9-45.1-3.2-18.7-2.6-37-6-56-6-46.8 0-73.5 38.7-73.5 82.6 0 87.8 80.4 101.3 150.4 101.3h48.2c70.3 0 150.6-13.4 150.6-101.3zm-82.6-55.1c-25.8 0-36.7 34.2-36.7 55.1s10.9 55.1 36.7 55.1 36.7-34.2 36.7-55.1-10.9-55.1-36.7-55.1z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/samsja19" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://www.linkedin.com/in/sami-jaghouar-805505193/" target="_blank" rel="noopener" title="www.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.tabs.sticky"], "search": "../../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.b4d07000.min.js"></script>
      
    
  <script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body>
</html>